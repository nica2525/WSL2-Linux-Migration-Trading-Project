#!/usr/bin/env python3
"""
Alpha Vantage APIçµ±åˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
- é«˜å“è³ªFXãƒ‡ãƒ¼ã‚¿å–å¾—
- ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆåˆ†æ
- çµŒæ¸ˆæŒ‡æ¨™çµ±åˆ
- ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿
"""

import requests
import pandas as pd
import numpy as np
import time
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Union, Tuple
import logging
from dataclasses import dataclass
from enum import Enum
import json
from pathlib import Path
import threading
import queue

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class DataInterval(Enum):
    """ãƒ‡ãƒ¼ã‚¿é–“éš”"""
    M1 = "1min"
    M5 = "5min"
    M15 = "15min"
    M30 = "30min"
    H1 = "60min"
    DAILY = "daily"
    WEEKLY = "weekly"
    MONTHLY = "monthly"

class MarketSentiment(Enum):
    """å¸‚å ´ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆ"""
    BULLISH = "Bullish"
    BEARISH = "Bearish"
    NEUTRAL = "Neutral"

@dataclass
class FXQuote:
    """FXä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿"""
    timestamp: datetime
    symbol: str
    bid: float
    ask: float
    volume: int = 0
    
    @property
    def mid_price(self) -> float:
        return (self.bid + self.ask) / 2
    
    @property
    def spread(self) -> float:
        return self.ask - self.bid

@dataclass
class SentimentData:
    """ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿"""
    symbol: str
    sentiment: MarketSentiment
    sentiment_score: float
    relevance_score: float
    ticker_sentiment_score: float
    timestamp: datetime

@dataclass
class EconomicIndicator:
    """çµŒæ¸ˆæŒ‡æ¨™ãƒ‡ãƒ¼ã‚¿"""
    name: str
    country: str
    value: float
    previous_value: Optional[float]
    forecast: Optional[float]
    timestamp: datetime
    importance: str  # HIGH, MEDIUM, LOW

class AlphaVantageClient:
    """Alpha Vantage APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ"""
    
    BASE_URL = "https://www.alphavantage.co/query"
    
    def __init__(self, api_key: str, cache_dir: str = "data_cache"):
        self.api_key = api_key
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(exist_ok=True)
        
        # ãƒ¬ãƒ¼ãƒˆåˆ¶é™ç®¡ç†ï¼ˆç„¡æ–™æ : 25 requests/dayï¼‰
        self.request_count = 0
        self.last_request_time = 0
        self.daily_limit = 25
        self.min_request_interval = 12  # 5åˆ†é–“ã«1å›
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³è¨­å®š
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'MT4-Python-Integration/1.0'
        })
        
        logger.info(f"Alpha Vantage ClientåˆæœŸåŒ–å®Œäº†: API Keyè¨­å®šæ¸ˆã¿")
    
    def _make_request(self, params: Dict) -> Optional[Dict]:
        """API ãƒªã‚¯ã‚¨ã‚¹ãƒˆå®Ÿè¡Œï¼ˆãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾å¿œï¼‰"""
        current_time = time.time()
        
        # ãƒ¬ãƒ¼ãƒˆåˆ¶é™ãƒã‚§ãƒƒã‚¯
        if self.request_count >= self.daily_limit:
            logger.warning("Alpha Vantage æ—¥æ¬¡ãƒªã‚¯ã‚¨ã‚¹ãƒˆåˆ¶é™ã«é”ã—ã¾ã—ãŸ")
            return None
        
        if current_time - self.last_request_time < self.min_request_interval:
            wait_time = self.min_request_interval - (current_time - self.last_request_time)
            logger.info(f"ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã«ã‚ˆã‚Š {wait_time:.1f}ç§’å¾…æ©Ÿ")
            time.sleep(wait_time)
        
        # APIã‚­ãƒ¼è¿½åŠ 
        params['apikey'] = self.api_key
        
        try:
            response = self.session.get(self.BASE_URL, params=params, timeout=30)
            response.raise_for_status()
            
            self.request_count += 1
            self.last_request_time = time.time()
            
            data = response.json()
            
            # ã‚¨ãƒ©ãƒ¼ãƒã‚§ãƒƒã‚¯
            if 'Error Message' in data:
                logger.error(f"Alpha Vantage API ã‚¨ãƒ©ãƒ¼: {data['Error Message']}")
                return None
            
            if 'Note' in data:
                logger.warning(f"Alpha Vantage API åˆ¶é™: {data['Note']}")
                return None
            
            return data
            
        except requests.RequestException as e:
            logger.error(f"Alpha Vantage API ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            return None
        except json.JSONDecodeError as e:
            logger.error(f"Alpha Vantage API ãƒ¬ã‚¹ãƒãƒ³ã‚¹è§£æã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def get_fx_intraday(self, from_symbol: str, to_symbol: str, 
                       interval: DataInterval = DataInterval.M5,
                       outputsize: str = "compact") -> Optional[pd.DataFrame]:
        """FXåˆ†è¶³ãƒ‡ãƒ¼ã‚¿å–å¾—"""
        cache_key = f"fx_intraday_{from_symbol}_{to_symbol}_{interval.value}_{outputsize}"
        cached_data = self._load_cache(cache_key)
        
        if cached_data is not None:
            logger.info(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿: {cache_key}")
            return cached_data
        
        params = {
            'function': 'FX_INTRADAY',
            'from_symbol': from_symbol,
            'to_symbol': to_symbol,
            'interval': interval.value,
            'outputsize': outputsize
        }
        
        data = self._make_request(params)
        if not data:
            return None
        
        try:
            # ã‚¿ã‚¤ãƒ ã‚·ãƒªãƒ¼ã‚ºãƒ‡ãƒ¼ã‚¿æŠ½å‡º
            time_series_key = f'Time Series FX ({interval.value})'
            if time_series_key not in data:
                logger.error(f"ã‚¿ã‚¤ãƒ ã‚·ãƒªãƒ¼ã‚ºãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {time_series_key}")
                return None
            
            time_series = data[time_series_key]
            
            # DataFrameå¤‰æ›
            df_data = []
            for timestamp_str, values in time_series.items():
                timestamp = pd.to_datetime(timestamp_str)
                df_data.append({
                    'timestamp': timestamp,
                    'open': float(values['1. open']),
                    'high': float(values['2. high']),
                    'low': float(values['3. low']),
                    'close': float(values['4. close'])
                })
            
            df = pd.DataFrame(df_data)
            df.set_index('timestamp', inplace=True)
            df.sort_index(inplace=True)
            
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜
            self._save_cache(cache_key, df)
            
            logger.info(f"FXåˆ†è¶³ãƒ‡ãƒ¼ã‚¿å–å¾—æˆåŠŸ: {from_symbol}/{to_symbol}, {len(df)}ãƒ¬ã‚³ãƒ¼ãƒ‰")
            return df
            
        except (KeyError, ValueError) as e:
            logger.error(f"FXåˆ†è¶³ãƒ‡ãƒ¼ã‚¿è§£æã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def get_fx_daily(self, from_symbol: str, to_symbol: str,
                    outputsize: str = "compact") -> Optional[pd.DataFrame]:
        """FXæ—¥è¶³ãƒ‡ãƒ¼ã‚¿å–å¾—"""
        cache_key = f"fx_daily_{from_symbol}_{to_symbol}_{outputsize}"
        cached_data = self._load_cache(cache_key)
        
        if cached_data is not None:
            return cached_data
        
        params = {
            'function': 'FX_DAILY',
            'from_symbol': from_symbol,
            'to_symbol': to_symbol,
            'outputsize': outputsize
        }
        
        data = self._make_request(params)
        if not data:
            return None
        
        try:
            time_series = data['Time Series FX (Daily)']
            
            df_data = []
            for timestamp_str, values in time_series.items():
                timestamp = pd.to_datetime(timestamp_str)
                df_data.append({
                    'timestamp': timestamp,
                    'open': float(values['1. open']),
                    'high': float(values['2. high']),
                    'low': float(values['3. low']),
                    'close': float(values['4. close'])
                })
            
            df = pd.DataFrame(df_data)
            df.set_index('timestamp', inplace=True)
            df.sort_index(inplace=True)
            
            self._save_cache(cache_key, df)
            
            logger.info(f"FXæ—¥è¶³ãƒ‡ãƒ¼ã‚¿å–å¾—æˆåŠŸ: {from_symbol}/{to_symbol}, {len(df)}ãƒ¬ã‚³ãƒ¼ãƒ‰")
            return df
            
        except (KeyError, ValueError) as e:
            logger.error(f"FXæ—¥è¶³ãƒ‡ãƒ¼ã‚¿è§£æã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def get_news_sentiment(self, tickers: Union[str, List[str]] = None,
                          topics: str = "forex",
                          time_from: str = None,
                          time_to: str = None,
                          limit: int = 50) -> List[SentimentData]:
        """ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆåˆ†æå–å¾—"""
        if isinstance(tickers, list):
            tickers = ','.join(tickers)
        
        params = {
            'function': 'NEWS_SENTIMENT',
            'topics': topics,
            'limit': limit
        }
        
        if tickers:
            params['tickers'] = tickers
        if time_from:
            params['time_from'] = time_from
        if time_to:
            params['time_to'] = time_to
        
        data = self._make_request(params)
        if not data:
            return []
        
        try:
            sentiment_data = []
            
            for item in data.get('feed', []):
                timestamp = pd.to_datetime(item['time_published'])
                
                # å…¨ä½“ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆ
                overall_sentiment_score = float(item.get('overall_sentiment_score', 0))
                overall_sentiment_label = item.get('overall_sentiment_label', 'Neutral')
                
                # ãƒ†ã‚£ãƒƒã‚«ãƒ¼åˆ¥ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆ
                for ticker_sentiment in item.get('ticker_sentiment', []):
                    ticker = ticker_sentiment.get('ticker', '')
                    if not ticker:
                        continue
                    
                    sentiment_data.append(SentimentData(
                        symbol=ticker,
                        sentiment=MarketSentiment(overall_sentiment_label),
                        sentiment_score=overall_sentiment_score,
                        relevance_score=float(ticker_sentiment.get('relevance_score', 0)),
                        ticker_sentiment_score=float(ticker_sentiment.get('ticker_sentiment_score', 0)),
                        timestamp=timestamp
                    ))
            
            logger.info(f"ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆå–å¾—æˆåŠŸ: {len(sentiment_data)}ä»¶")
            return sentiment_data
            
        except (KeyError, ValueError) as e:
            logger.error(f"ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆè§£æã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    def get_economic_indicators(self, indicator: str = "GDP",
                              interval: str = "quarterly") -> List[EconomicIndicator]:
        """çµŒæ¸ˆæŒ‡æ¨™ãƒ‡ãƒ¼ã‚¿å–å¾—"""
        params = {
            'function': indicator,
            'interval': interval
        }
        
        data = self._make_request(params)
        if not data:
            return []
        
        try:
            indicators = []
            
            # ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã¯æŒ‡æ¨™ã«ã‚ˆã‚Šç•°ãªã‚‹ãŸã‚ã€æŸ”è»Ÿã«å‡¦ç†
            data_key = None
            for key in data.keys():
                if 'data' in key.lower():
                    data_key = key
                    break
            
            if not data_key:
                logger.warning(f"çµŒæ¸ˆæŒ‡æ¨™ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {indicator}")
                return []
            
            for item in data[data_key]:
                timestamp = pd.to_datetime(item.get('date', ''))
                value = float(item.get('value', 0))
                
                indicators.append(EconomicIndicator(
                    name=indicator,
                    country="US",  # Alpha Vantageã¯ä¸»ã«USæŒ‡æ¨™
                    value=value,
                    previous_value=None,  # Alpha Vantageã§ã¯æä¾›ã•ã‚Œãªã„
                    forecast=None,
                    timestamp=timestamp,
                    importance="HIGH"  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
                ))
            
            logger.info(f"çµŒæ¸ˆæŒ‡æ¨™å–å¾—æˆåŠŸ: {indicator}, {len(indicators)}ä»¶")
            return indicators
            
        except (KeyError, ValueError) as e:
            logger.error(f"çµŒæ¸ˆæŒ‡æ¨™è§£æã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    def _load_cache(self, cache_key: str) -> Optional[pd.DataFrame]:
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿"""
        cache_file = self.cache_dir / f"{cache_key}.pkl"
        
        if not cache_file.exists():
            return None
        
        try:
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®æœ‰åŠ¹æœŸé™ãƒã‚§ãƒƒã‚¯ï¼ˆ1æ™‚é–“ï¼‰
            if time.time() - cache_file.stat().st_mtime > 3600:
                return None
            
            df = pd.read_pickle(cache_file)
            return df
            
        except Exception as e:
            logger.warning(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def _save_cache(self, cache_key: str, df: pd.DataFrame):
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ãƒ¼ã‚¿ä¿å­˜"""
        cache_file = self.cache_dir / f"{cache_key}.pkl"
        
        try:
            df.to_pickle(cache_file)
        except Exception as e:
            logger.warning(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")

class MarketDataEnhancer:
    """Alpha Vantageãƒ‡ãƒ¼ã‚¿ã§ã®ãƒãƒ¼ã‚±ãƒƒãƒˆãƒ‡ãƒ¼ã‚¿å¼·åŒ–"""
    
    def __init__(self, alpha_vantage_client: AlphaVantageClient):
        self.client = alpha_vantage_client
        self.sentiment_cache = {}
        self.economic_cache = {}
        
    def enhance_price_data(self, symbol_pair: str, 
                          local_data: pd.DataFrame) -> pd.DataFrame:
        """ãƒ­ãƒ¼ã‚«ãƒ«ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã‚’Alpha Vantageãƒ‡ãƒ¼ã‚¿ã§å¼·åŒ–"""
        try:
            # ã‚·ãƒ³ãƒœãƒ«åˆ†å‰² (ä¾‹: EURUSD -> EUR, USD)
            if len(symbol_pair) == 6:
                from_symbol = symbol_pair[:3]
                to_symbol = symbol_pair[3:]
            else:
                logger.warning(f"ç„¡åŠ¹ãªã‚·ãƒ³ãƒœãƒ«å½¢å¼: {symbol_pair}")
                return local_data
            
            # Alpha Vantageã‹ã‚‰æ—¥è¶³ãƒ‡ãƒ¼ã‚¿å–å¾—
            av_data = self.client.get_fx_daily(from_symbol, to_symbol)
            
            if av_data is None or av_data.empty:
                logger.warning("Alpha Vantageãƒ‡ãƒ¼ã‚¿å–å¾—å¤±æ•—ã€ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ãã®ã¾ã¾è¿”ã™")
                return local_data
            
            # ãƒ‡ãƒ¼ã‚¿ãƒãƒ¼ã‚¸
            enhanced_data = local_data.copy()
            
            # Alpha Vantageãƒ‡ãƒ¼ã‚¿ã‹ã‚‰è¿½åŠ æƒ…å ±ã‚’æŠ½å‡º
            latest_av_date = av_data.index[-1].date()
            latest_local_date = enhanced_data.index[-1].date()
            
            if latest_av_date > latest_local_date:
                logger.info("Alpha Vantageã«ã‚ˆã‚Šæ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨")
                # æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ ã™ã‚‹å‡¦ç†ã‚’ã“ã“ã«å®Ÿè£…
            
            # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£æŒ‡æ¨™è¿½åŠ 
            av_returns = av_data['close'].pct_change()
            av_volatility = av_returns.rolling(window=20).std()
            
            # æœ€æ–°ã®ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚’ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‡ãƒ¼ã‚¿ã«è¿½åŠ 
            if not av_volatility.empty:
                latest_volatility = av_volatility.iloc[-1]
                enhanced_data['alpha_vantage_volatility'] = latest_volatility
            
            return enhanced_data
            
        except Exception as e:
            logger.error(f"ãƒ‡ãƒ¼ã‚¿å¼·åŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            return local_data
    
    def get_market_sentiment_score(self, symbol: str) -> float:
        """å¸‚å ´ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆã‚¹ã‚³ã‚¢å–å¾—"""
        try:
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯
            if symbol in self.sentiment_cache:
                cache_time, sentiment_score = self.sentiment_cache[symbol]
                if time.time() - cache_time < 3600:  # 1æ™‚é–“ã‚­ãƒ£ãƒƒã‚·ãƒ¥
                    return sentiment_score
            
            # ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿å–å¾—
            sentiment_data = self.client.get_news_sentiment(tickers=symbol)
            
            if not sentiment_data:
                return 0.0  # ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«
            
            # æœ€æ–°ã®ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆã‚¹ã‚³ã‚¢è¨ˆç®—
            recent_sentiments = [s for s in sentiment_data 
                               if (datetime.now() - s.timestamp).days <= 1]
            
            if not recent_sentiments:
                return 0.0
            
            # é‡ã¿ä»˜ãå¹³å‡ï¼ˆé–¢é€£åº¦ã§é‡ã¿ä»˜ã‘ï¼‰
            total_score = sum(s.ticker_sentiment_score * s.relevance_score 
                            for s in recent_sentiments)
            total_weight = sum(s.relevance_score for s in recent_sentiments)
            
            sentiment_score = total_score / total_weight if total_weight > 0 else 0.0
            
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ›´æ–°
            self.sentiment_cache[symbol] = (time.time(), sentiment_score)
            
            return sentiment_score
            
        except Exception as e:
            logger.error(f"ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆã‚¹ã‚³ã‚¢å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return 0.0

def create_sample_integration():
    """Alpha Vantageçµ±åˆã®ã‚µãƒ³ãƒ—ãƒ«å®Ÿè£…"""
    print("ğŸŒŸ Alpha Vantage APIçµ±åˆã‚µãƒ³ãƒ—ãƒ«")
    print("=" * 50)
    
    # ã‚µãƒ³ãƒ—ãƒ«ç”¨ã®APIã‚­ãƒ¼ï¼ˆå®Ÿéš›ã®ä½¿ç”¨æ™‚ã¯ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—ï¼‰
    api_key = "demo"  # å®Ÿéš›ã®APIã‚­ãƒ¼ã«ç½®ãæ›ãˆã¦ãã ã•ã„
    
    try:
        # ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
        client = AlphaVantageClient(api_key)
        
        # FXãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ†ã‚¹ãƒˆ
        print("\nğŸ“Š EURUSD 5åˆ†è¶³ãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ†ã‚¹ãƒˆ...")
        fx_data = client.get_fx_intraday("EUR", "USD", DataInterval.M5)
        
        if fx_data is not None:
            print(f"âœ… ãƒ‡ãƒ¼ã‚¿å–å¾—æˆåŠŸ: {len(fx_data)}ãƒ¬ã‚³ãƒ¼ãƒ‰")
            print(fx_data.tail())
        else:
            print("âŒ ãƒ‡ãƒ¼ã‚¿å–å¾—å¤±æ•—")
        
        # ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆåˆ†æãƒ†ã‚¹ãƒˆ
        print("\nğŸ“° ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆåˆ†æãƒ†ã‚¹ãƒˆ...")
        sentiment_data = client.get_news_sentiment(topics="forex", limit=10)
        
        if sentiment_data:
            print(f"âœ… ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆå–å¾—æˆåŠŸ: {len(sentiment_data)}ä»¶")
            for s in sentiment_data[:3]:
                print(f"   {s.symbol}: {s.sentiment.value} (ã‚¹ã‚³ã‚¢: {s.sentiment_score:.3f})")
        else:
            print("âŒ ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆå–å¾—å¤±æ•—")
        
        # ãƒ‡ãƒ¼ã‚¿å¼·åŒ–ãƒ†ã‚¹ãƒˆ
        print("\nğŸš€ ãƒ‡ãƒ¼ã‚¿å¼·åŒ–æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ...")
        enhancer = MarketDataEnhancer(client)
        
        # ã‚µãƒ³ãƒ—ãƒ«ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‡ãƒ¼ã‚¿
        sample_data = pd.DataFrame({
            'open': [1.1000, 1.1010, 1.1005],
            'high': [1.1015, 1.1020, 1.1015],
            'low': [1.0995, 1.1005, 1.1000],
            'close': [1.1010, 1.1005, 1.1012]
        }, index=pd.date_range('2025-01-01', periods=3, freq='H'))
        
        enhanced_data = enhancer.enhance_price_data("EURUSD", sample_data)
        print(f"âœ… ãƒ‡ãƒ¼ã‚¿å¼·åŒ–å®Œäº†: {enhanced_data.columns.tolist()}")
        
    except Exception as e:
        print(f"âŒ çµ±åˆãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")

if __name__ == "__main__":
    create_sample_integration()