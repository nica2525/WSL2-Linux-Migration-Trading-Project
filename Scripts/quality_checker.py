#!/usr/bin/env python3
"""
å“è³ªãƒã‚§ãƒƒã‚¯ã‚·ã‚¹ãƒ†ãƒ ï¼ˆCronçµ±åˆå¯¾å¿œï¼‰
æ—¢å­˜ã®Cronè‡ªå‹•ä¿å­˜ã‚·ã‚¹ãƒ†ãƒ ã¨é€£æºã—ã¦å“è³ªå•é¡Œã‚’æ¤œå‡ºãƒ»è¨˜éŒ²
"""

import os
import subprocess
import json
from datetime import datetime
from pathlib import Path
import re


class QualityChecker:
    def __init__(self, project_dir):
        self.project_dir = Path(project_dir)
        self.quality_log = self.project_dir / ".quality_issues.json"
        self.scan_patterns = {
            "random_generation": {
                "pattern": r"random\.random\(\)\s*<\s*0\.\d+",
                "severity": "HIGH", 
                "description": "ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆçµæœã®ãƒ©ãƒ³ãƒ€ãƒ ç”Ÿæˆï¼ˆå½è£…ï¼‰"
            },
            "lookahead_bias": {
                "pattern": r"current_bar\[.close.\]",
                "severity": "HIGH",
                "description": "Look-ahead biasï¼ˆæœªæ¥ãƒ‡ãƒ¼ã‚¿å‚ç…§ï¼‰",
                "false_positive_contexts": [
                    r"bar_close\s*=\s*current_bar\[.close.\]",  # ãƒãƒ¼çµ‚å€¤å–å¾—
                    r"exit_price\s*=\s*bar_close",  # æ™‚é–“åˆ‡ã‚Œæ±ºæ¸ˆ
                    r"TIME_EXIT",  # æ™‚é–“åˆ‡ã‚Œæ±ºæ¸ˆã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
                    r"max_holding_hours",  # æœ€å¤§ä¿æœ‰æ™‚é–“é–¢é€£
                    r"final_price\s*=.*\[.close.\]",  # æœ€çµ‚æ±ºæ¸ˆ
                    r"FORCED_EXIT",  # å¼·åˆ¶æ±ºæ¸ˆ
                    r"check_exit.*def",  # æ±ºæ¸ˆåˆ¤å®šé–¢æ•°
                    r"hours_held.*>=.*max_holding"  # æ™‚é–“åˆ¶é™ãƒã‚§ãƒƒã‚¯
                ]
            },
            "random_uniform_suspicious": {
                "pattern": r"random\.uniform\(.*return",
                "severity": "MEDIUM",
                "description": "æˆ¦ç•¥çµæœã§ã®random.uniformä½¿ç”¨"
            },
            "fixed_winrate": {
                "pattern": r"random\.random\(\)\s*<\s*0\.[34]\d+.*win",
                "severity": "HIGH", 
                "description": "å›ºå®šå‹ç‡ã«ã‚ˆã‚‹ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆå½è£…"
            },
            "future_price_access": {
                "pattern": r"current_price\s*=\s*current_bar\[.close.\]",
                "severity": "HIGH",
                "description": "ã‚·ã‚°ãƒŠãƒ«ç”Ÿæˆæ™‚ã®æœªæ¥ä¾¡æ ¼å‚ç…§"
            },
            "simulation_bias": {
                "pattern": r"if\s+random\.random\(\)\s*<\s*0\.[5-9]",
                "severity": "MEDIUM",
                "description": "ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çµæœã®äººå·¥çš„æ“ä½œ"
            }
        }

    def scan_quality_issues(self):
        """å“è³ªå•é¡Œã‚¹ã‚­ãƒ£ãƒ³å®Ÿè¡Œ"""
        issues = []
        
        # Python ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¹ã‚­ãƒ£ãƒ³
        py_files = list(self.project_dir.glob("**/*.py"))
        
        for py_file in py_files:
            # Archive/Skip ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¯é™¤å¤–
            if "Archive" in str(py_file) or "Archive" in str(py_file):
                continue
                
            try:
                with open(py_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                    
                for issue_type, config in self.scan_patterns.items():
                    matches = re.finditer(config["pattern"], content, re.IGNORECASE | re.MULTILINE)
                    
                    for match in matches:
                        line_num = content[:match.start()].count('\n') + 1
                        
                        # False positive ãƒã‚§ãƒƒã‚¯
                        if self._is_false_positive(match, content, config, line_num):
                            continue
                            
                        # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±å–å¾—
                        context_info = self._get_context_info(content, match.start(), line_num)
                        
                        issue = {
                            "timestamp": datetime.now().isoformat(),
                            "file": str(py_file.relative_to(self.project_dir)),
                            "line": line_num,
                            "type": issue_type,
                            "severity": config["severity"],
                            "description": config["description"],
                            "code_snippet": match.group(0)[:100],
                            "context": context_info,
                            "confidence": self._calculate_confidence(match, content, config)
                        }
                        issues.append(issue)
                        
            except Exception as e:
                print(f"Error scanning {py_file}: {e}")
                
        return issues
    
    def _is_false_positive(self, match, content, config, line_num):
        """False positive åˆ¤å®š"""
        if "false_positive_contexts" not in config:
            return False
            
        # ãƒãƒƒãƒå‘¨è¾ºã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå–å¾—ï¼ˆå‰å¾Œ5è¡Œï¼‰
        lines = content.split('\n')
        start_line = max(0, line_num - 6)
        end_line = min(len(lines), line_num + 5)
        context = '\n'.join(lines[start_line:end_line])
        
        # False positive ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒã‚§ãƒƒã‚¯
        for fp_pattern in config["false_positive_contexts"]:
            if re.search(fp_pattern, context, re.IGNORECASE):
                return True
                
        return False
    
    def _get_context_info(self, content, match_start, line_num):
        """ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±å–å¾—"""
        lines = content.split('\n')
        current_line = lines[line_num - 1] if line_num > 0 else ""
        
        # é–¢æ•°åæ¤œç´¢
        function_name = "unknown"
        for i in range(line_num - 1, max(0, line_num - 20), -1):
            if i < len(lines):
                line = lines[i]
                func_match = re.search(r'def\s+(\w+)', line)
                if func_match:
                    function_name = func_match.group(1)
                    break
        
        # ã‚¯ãƒ©ã‚¹åæ¤œç´¢
        class_name = "unknown"
        for i in range(line_num - 1, max(0, line_num - 50), -1):
            if i < len(lines):
                line = lines[i]
                class_match = re.search(r'class\s+(\w+)', line)
                if class_match:
                    class_name = class_match.group(1)
                    break
        
        return {
            "function": function_name,
            "class": class_name,
            "line_content": current_line.strip()
        }
    
    def _calculate_confidence(self, match, content, config):
        """ä¿¡é ¼åº¦è¨ˆç®—"""
        # åŸºæœ¬ä¿¡é ¼åº¦
        confidence = 0.8
        
        # ã‚·ã‚°ãƒŠãƒ«ç”Ÿæˆé–¢æ•°å†…ãªã‚‰ä¿¡é ¼åº¦å‘ä¸Š
        if "generate_signal" in content or "signal" in match.group(0).lower():
            confidence += 0.1
            
        # ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆé–¢æ•°å†…ãªã‚‰ä¿¡é ¼åº¦å‘ä¸Š
        if "backtest" in content or "test_" in content:
            confidence += 0.1
            
        return min(1.0, confidence)

    def load_previous_issues(self):
        """å‰å›ã®å“è³ªå•é¡Œè¨˜éŒ²ã‚’èª­ã¿è¾¼ã¿"""
        if not self.quality_log.exists():
            return []
            
        try:
            with open(self.quality_log, 'r') as f:
                return json.load(f)
        except:
            return []

    def save_issues(self, issues):
        """å“è³ªå•é¡Œè¨˜éŒ²ã‚’ä¿å­˜"""
        with open(self.quality_log, 'w') as f:
            json.dump(issues, f, indent=2, ensure_ascii=False)

    def generate_quality_report(self):
        """å“è³ªãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        issues = self.scan_quality_issues()
        previous_issues = self.load_previous_issues()
        
        # å‰å›ã‹ã‚‰ã®å¤‰åŒ–ã‚’æ¤œå‡º
        current_signatures = {f"{issue['file']}:{issue['line']}:{issue['type']}" for issue in issues}
        previous_signatures = {f"{issue['file']}:{issue['line']}:{issue['type']}" for issue in previous_issues}
        
        new_issues = [issue for issue in issues 
                     if f"{issue['file']}:{issue['line']}:{issue['type']}" not in previous_signatures]
        fixed_issues = previous_signatures - current_signatures
        
        # é‡è¦åº¦åˆ¥çµ±è¨ˆ
        high_issues = [issue for issue in issues if issue['severity'] == 'HIGH']
        medium_issues = [issue for issue in issues if issue['severity'] == 'MEDIUM']
        
        report = {
            "scan_timestamp": datetime.now().isoformat(),
            "summary": {
                "total_issues": len(issues),
                "high_severity": len(high_issues),
                "medium_severity": len(medium_issues),
                "new_issues": len(new_issues),
                "fixed_issues": len(fixed_issues)
            },
            "new_issues": new_issues,
            "fixed_issues": list(fixed_issues),
            "all_issues": issues
        }
        
        # è¨˜éŒ²ã‚’ä¿å­˜
        self.save_issues(issues)
        
        return report

    def create_session_quality_briefing(self):
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹æ™‚ç”¨ã®å“è³ªæ¦‚è¦ä½œæˆ"""
        report = self.generate_quality_report()
        
        briefing = []
        briefing.append("ğŸ” å“è³ªçŠ¶æ³ã‚µãƒãƒªãƒ¼")
        briefing.append(f"   ç·å•é¡Œæ•°: {report['summary']['total_issues']}")
        briefing.append(f"   é«˜é‡è¦åº¦: {report['summary']['high_severity']}")
        briefing.append(f"   æ–°è¦å•é¡Œ: {report['summary']['new_issues']}")
        briefing.append(f"   ä¿®æ­£æ¸ˆã¿: {report['summary']['fixed_issues']}")
        
        if report['summary']['high_severity'] > 0:
            briefing.append("\nğŸš¨ ç·Šæ€¥ä¿®æ­£è¦ä»¶:")
            for issue in report['all_issues']:
                if issue['severity'] == 'HIGH':
                    confidence_badge = "ğŸ”´" if issue.get('confidence', 0.8) > 0.9 else "ğŸŸ¡"
                    context = issue.get('context', {})
                    func_info = f" [{context.get('function', 'unknown')}]" if context.get('function') != 'unknown' else ""
                    briefing.append(f"   {confidence_badge} {issue['file']}:{issue['line']} - {issue['description']}{func_info}")
        
        if report['summary']['new_issues'] > 0:
            briefing.append("\nğŸ†• æ–°è¦ç™ºè¦‹å•é¡Œ:")
            for issue in report['new_issues']:
                briefing.append(f"   {issue['file']}:{issue['line']} - {issue['description']}")
        
        if report['summary']['total_issues'] == 0:
            briefing.append("\nâœ… å“è³ªå•é¡Œãªã— - è‰¯å¥½ãªçŠ¶æ…‹ã‚’ç¶­æŒ")
            
        return "\n".join(briefing)
    
    def generate_detailed_analysis(self):
        """è©³ç´°å“è³ªåˆ†æãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        report = self.generate_quality_report()
        
        analysis = {
            "timestamp": datetime.now().isoformat(),
            "summary": report['summary'],
            "file_statistics": {},
            "severity_breakdown": {},
            "confidence_analysis": {},
            "pattern_frequency": {},
            "false_positive_rate": 0.0
        }
        
        # ãƒ•ã‚¡ã‚¤ãƒ«åˆ¥çµ±è¨ˆ
        file_issues = {}
        for issue in report['all_issues']:
            file_name = issue['file']
            if file_name not in file_issues:
                file_issues[file_name] = []
            file_issues[file_name].append(issue)
        
        analysis['file_statistics'] = {
            file: {
                "issue_count": len(issues),
                "high_severity": len([i for i in issues if i['severity'] == 'HIGH']),
                "avg_confidence": sum(i.get('confidence', 0.8) for i in issues) / len(issues) if issues else 0
            } for file, issues in file_issues.items()
        }
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³é »åº¦åˆ†æ
        pattern_count = {}
        for issue in report['all_issues']:
            pattern = issue['type']
            pattern_count[pattern] = pattern_count.get(pattern, 0) + 1
        analysis['pattern_frequency'] = pattern_count
        
        # ä¿¡é ¼åº¦åˆ†æ
        confidences = [issue.get('confidence', 0.8) for issue in report['all_issues']]
        if confidences:
            analysis['confidence_analysis'] = {
                "avg_confidence": sum(confidences) / len(confidences),
                "high_confidence_issues": len([c for c in confidences if c > 0.9]),
                "low_confidence_issues": len([c for c in confidences if c < 0.7])
            }
        
        return analysis
    
    def create_improvement_suggestions(self):
        """æ”¹å–„ææ¡ˆç”Ÿæˆ"""
        analysis = self.generate_detailed_analysis()
        suggestions = []
        
        # é«˜é‡è¦åº¦å•é¡Œã®ææ¡ˆ
        if analysis['summary']['high_severity'] > 0:
            suggestions.append("ğŸš¨ é«˜é‡è¦åº¦å•é¡Œã®å³åº§ä¿®æ­£ã‚’æ¨å¥¨")
            suggestions.append("   - Look-ahead bias: ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆåˆ¤å®šã‚’high/lowãƒ™ãƒ¼ã‚¹ã«å¤‰æ›´")
            suggestions.append("   - Random generation: å®Ÿéš›ã®ä¾¡æ ¼è¿½è·¡ãƒ­ã‚¸ãƒƒã‚¯ã«ç½®æ›")
        
        # ãƒ•ã‚¡ã‚¤ãƒ«åˆ¥ææ¡ˆ
        worst_files = sorted(
            analysis['file_statistics'].items(),
            key=lambda x: x[1]['issue_count'],
            reverse=True
        )[:3]
        
        if worst_files:
            suggestions.append(f"\nğŸ“ æœ€å„ªå…ˆä¿®æ­£ãƒ•ã‚¡ã‚¤ãƒ«:")
            for file, stats in worst_files:
                suggestions.append(f"   - {file}: {stats['issue_count']}ä»¶ã®å•é¡Œ")
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ¥ææ¡ˆ
        frequent_patterns = sorted(
            analysis['pattern_frequency'].items(),
            key=lambda x: x[1],
            reverse=True
        )[:2]
        
        if frequent_patterns:
            suggestions.append(f"\nğŸ” æœ€é »å‡ºãƒ‘ã‚¿ãƒ¼ãƒ³:")
            for pattern, count in frequent_patterns:
                suggestions.append(f"   - {pattern}: {count}ä»¶")
        
        return "\n".join(suggestions)


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œï¼ˆCronå¯¾å¿œï¼‰"""
    project_dir = "/mnt/e/Trading-Development/2.ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆæ‰‹æ³•ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ"
    checker = QualityChecker(project_dir)
    
    # å“è³ªãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    report = checker.generate_quality_report()
    
    # ã‚³ãƒ³ã‚½ãƒ¼ãƒ«å‡ºåŠ›ï¼ˆCronãƒ­ã‚°ç”¨ï¼‰
    print(f"å“è³ªãƒã‚§ãƒƒã‚¯å®Œäº†: {report['summary']['total_issues']}ä»¶ã®å•é¡Œã‚’æ¤œå‡º")
    
    if report['summary']['high_severity'] > 0:
        print(f"ğŸš¨ ç·Šæ€¥å¯¾å¿œè¦: {report['summary']['high_severity']}ä»¶ã®é«˜é‡è¦åº¦å•é¡Œ")
    
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³ç”¨æ¦‚è¦ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
    briefing = checker.create_session_quality_briefing()
    briefing_file = Path(project_dir) / "CURRENT_QUALITY_STATUS.md"
    
    # æ”¹å–„ææ¡ˆç”Ÿæˆ
    suggestions = checker.create_improvement_suggestions()
    
    # è©³ç´°åˆ†æç”Ÿæˆ
    analysis = checker.generate_detailed_analysis()
    
    with open(briefing_file, 'w', encoding='utf-8') as f:
        f.write(f"# ç¾åœ¨ã®å“è³ªçŠ¶æ³\n\n{briefing}\n\n")
        
        if suggestions:
            f.write(f"## ğŸ¯ æ”¹å–„ææ¡ˆ\n{suggestions}\n\n")
        
        # ä¿¡é ¼åº¦çµ±è¨ˆ
        if 'confidence_analysis' in analysis and analysis['confidence_analysis']:
            conf = analysis['confidence_analysis']
            f.write(f"## ğŸ“Š æ¤œå‡ºç²¾åº¦\n")
            f.write(f"- å¹³å‡ä¿¡é ¼åº¦: {conf['avg_confidence']:.1%}\n")
            f.write(f"- é«˜ä¿¡é ¼åº¦å•é¡Œ: {conf['high_confidence_issues']}ä»¶\n")
            f.write(f"- è¦ç¢ºèªå•é¡Œ: {conf['low_confidence_issues']}ä»¶\n\n")
        
        f.write(f"æœ€çµ‚æ›´æ–°: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
    
    # è©³ç´°åˆ†æã‚’JSONã§ä¿å­˜
    analysis_file = Path(project_dir) / ".quality_analysis.json"
    with open(analysis_file, 'w', encoding='utf-8') as f:
        json.dump(analysis, f, indent=2, ensure_ascii=False)
    
    return report


if __name__ == "__main__":
    main()