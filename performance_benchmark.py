#!/usr/bin/env python3
"""
Phase2 æ€§èƒ½ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ†ã‚¹ãƒˆ
kiroè¦ä»¶æº–æ‹ : ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ»ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆæ¸¬å®š
"""

import asyncio
import time
import statistics
from datetime import datetime, timedelta
from typing import List
import sys
from pathlib import Path

sys.path.append(str(Path(__file__).parent))
from realtime_signal_generator import (
    MarketDataFeed, SignalGenerator, MarketData, RealtimeSignalSystem
)

class PerformanceBenchmark:
    """æ€§èƒ½ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯"""
    
    def __init__(self):
        self.results = {}
        
    async def benchmark_signal_generation_latency(self) -> float:
        """ã‚·ã‚°ãƒŠãƒ«ç”Ÿæˆãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯"""
        print("ğŸ“Š ã‚·ã‚°ãƒŠãƒ«ç”Ÿæˆãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯é–‹å§‹...")
        
        feed = MarketDataFeed()
        generator = SignalGenerator(feed)
        
        # å±¥æ­´ãƒ‡ãƒ¼ã‚¿æº–å‚™
        base_time = datetime.now()
        for i in range(25):
            data = MarketData(
                timestamp=base_time + timedelta(minutes=i),
                symbol='EURUSD',
                open=1.1000 + i * 0.0001,
                high=1.1010 + i * 0.0001,
                low=1.0990 + i * 0.0001,
                close=1.1005 + i * 0.0001,
                volume=1000
            )
            with feed.buffer_lock:
                feed.data_buffer.append(data)
        
        # ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆãƒ‡ãƒ¼ã‚¿æº–å‚™
        breakout_data = MarketData(
            timestamp=base_time + timedelta(minutes=26),
            symbol='EURUSD',
            open=1.1050,
            high=1.1100,  # å¼·ã„ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆ
            low=1.0995,
            close=1.1095,
            volume=1500
        )
        
        # ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·æ¸¬å®šï¼ˆ100å›å®Ÿè¡Œï¼‰
        latencies = []
        for i in range(100):
            start_time = asyncio.get_event_loop().time()
            signal = await generator._detect_breakout_signal(breakout_data)
            end_time = asyncio.get_event_loop().time()
            
            latency_ms = (end_time - start_time) * 1000
            latencies.append(latency_ms)
        
        # çµ±è¨ˆè¨ˆç®—
        avg_latency = statistics.mean(latencies)
        max_latency = max(latencies)
        min_latency = min(latencies)
        p95_latency = statistics.quantiles(latencies, n=20)[18]  # 95ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«
        
        self.results['signal_generation'] = {
            'average_ms': avg_latency,
            'max_ms': max_latency,
            'min_ms': min_latency,
            'p95_ms': p95_latency,
            'requirement_met': avg_latency < 100
        }
        
        print(f"  å¹³å‡ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·: {avg_latency:.2f}ms")
        print(f"  æœ€å¤§ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·: {max_latency:.2f}ms")
        print(f"  95ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«: {p95_latency:.2f}ms")
        print(f"  è¦ä»¶é”æˆ (<100ms): {'âœ…' if avg_latency < 100 else 'âŒ'}")
        
        return avg_latency
    
    async def benchmark_data_processing_throughput(self) -> float:
        """ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯"""
        print("\nğŸ“Š ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯é–‹å§‹...")
        
        feed = MarketDataFeed()
        
        # 1000ãƒ‡ãƒ¼ã‚¿ã®å‡¦ç†æ™‚é–“æ¸¬å®š
        data_count = 1000
        start_time = time.time()
        
        for i in range(data_count):
            test_data = {
                'timestamp': (datetime.now() + timedelta(milliseconds=i)).isoformat(),
                'symbol': 'EURUSD',
                'open': 1.1000,
                'high': 1.1010,
                'low': 1.0990,
                'close': 1.1005,
                'volume': 1000
            }
            await feed._process_market_data(test_data)
        
        end_time = time.time()
        processing_time = end_time - start_time
        throughput = data_count / processing_time
        
        self.results['data_processing'] = {
            'data_count': data_count,
            'processing_time_s': processing_time,
            'throughput_per_sec': throughput,
            'requirement_met': throughput >= 1000
        }
        
        print(f"  å‡¦ç†ãƒ‡ãƒ¼ã‚¿æ•°: {data_count}")
        print(f"  å‡¦ç†æ™‚é–“: {processing_time:.3f}s")
        print(f"  ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ: {throughput:.1f} ãƒ‡ãƒ¼ã‚¿/ç§’")
        print(f"  è¦ä»¶é”æˆ (â‰¥1000/ç§’): {'âœ…' if throughput >= 1000 else 'âŒ'}")
        
        return throughput
    
    async def benchmark_memory_usage(self) -> dict:
        """ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ï¼ˆç°¡æ˜“ç‰ˆï¼‰"""
        print("\nğŸ“Š ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯é–‹å§‹...")
        
        # ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
        system = RealtimeSignalSystem()
        
        # ãƒãƒƒãƒ•ã‚¡ã‚µã‚¤ã‚ºãƒ†ã‚¹ãƒˆ
        feed = system.market_feed
        initial_buffer_size = len(feed.data_buffer)
        
        # å¤§é‡ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        for i in range(10000):
            test_data = {
                'timestamp': (datetime.now() + timedelta(milliseconds=i)).isoformat(),
                'symbol': 'EURUSD',
                'open': 1.1000,
                'high': 1.1010,
                'low': 1.0990,
                'close': 1.1005,
                'volume': 1000
            }
            await feed._process_market_data(test_data)
        
        final_buffer_size = len(feed.data_buffer)
        
        self.results['memory_usage'] = {
            'initial_buffer_size': initial_buffer_size,
            'final_buffer_size': final_buffer_size,
            'data_processed': 10000,
            'buffer_managed': final_buffer_size <= 10000  # ãƒãƒƒãƒ•ã‚¡åˆ¶é™ç¢ºèª
        }
        
        print(f"  åˆæœŸãƒãƒƒãƒ•ã‚¡ã‚µã‚¤ã‚º: {initial_buffer_size}")
        print(f"  æœ€çµ‚ãƒãƒƒãƒ•ã‚¡ã‚µã‚¤ã‚º: {final_buffer_size}")
        print(f"  å‡¦ç†ãƒ‡ãƒ¼ã‚¿æ•°: 10000")
        print(f"  ãƒãƒƒãƒ•ã‚¡ç®¡ç†: {'âœ… åˆ¶é™å†…' if final_buffer_size <= 10000 else 'âŒ åˆ¶é™è¶…é'}")
        
        return self.results['memory_usage']
    
    async def benchmark_concurrent_processing(self) -> dict:
        """ä¸¦è¡Œå‡¦ç†æ€§èƒ½ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯"""
        print("\nğŸ“Š ä¸¦è¡Œå‡¦ç†æ€§èƒ½ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯é–‹å§‹...")
        
        async def process_symbol_data(symbol: str, count: int):
            """ã‚·ãƒ³ãƒœãƒ«åˆ¥ãƒ‡ãƒ¼ã‚¿å‡¦ç†"""
            feed = MarketDataFeed()
            start_time = time.time()
            
            for i in range(count):
                test_data = {
                    'timestamp': (datetime.now() + timedelta(milliseconds=i)).isoformat(),
                    'symbol': symbol,
                    'open': 1.1000,
                    'high': 1.1010,
                    'low': 1.0990,
                    'close': 1.1005,
                    'volume': 1000
                }
                await feed._process_market_data(test_data)
            
            end_time = time.time()
            return end_time - start_time
        
        # 5ã‚·ãƒ³ãƒœãƒ«åŒæ™‚å‡¦ç†
        symbols = ['EURUSD', 'USDJPY', 'GBPUSD', 'USDCAD', 'AUDUSD']
        data_per_symbol = 200
        
        start_time = time.time()
        tasks = [process_symbol_data(symbol, data_per_symbol) for symbol in symbols]
        processing_times = await asyncio.gather(*tasks)
        total_time = time.time() - start_time
        
        total_data = len(symbols) * data_per_symbol
        concurrent_throughput = total_data / total_time
        
        self.results['concurrent_processing'] = {
            'symbols': len(symbols),
            'data_per_symbol': data_per_symbol,
            'total_data': total_data,
            'total_time_s': total_time,
            'concurrent_throughput': concurrent_throughput,
            'processing_times': dict(zip(symbols, processing_times))
        }
        
        print(f"  ã‚·ãƒ³ãƒœãƒ«æ•°: {len(symbols)}")
        print(f"  ç·ãƒ‡ãƒ¼ã‚¿æ•°: {total_data}")
        print(f"  ç·å‡¦ç†æ™‚é–“: {total_time:.3f}s")
        print(f"  ä¸¦è¡Œã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ: {concurrent_throughput:.1f} ãƒ‡ãƒ¼ã‚¿/ç§’")
        
        return self.results['concurrent_processing']
    
    def generate_performance_report(self):
        """æ€§èƒ½ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        print("\n" + "="*60)
        print("ğŸ“‹ Phase2 æ€§èƒ½ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœã‚µãƒãƒªãƒ¼")
        print("="*60)
        
        # è¦ä»¶é”æˆç¢ºèª
        requirements_met = []
        
        if 'signal_generation' in self.results:
            sg = self.results['signal_generation']
            requirements_met.append(('ã‚·ã‚°ãƒŠãƒ«ç”Ÿæˆãƒ¬ã‚¤ãƒ†ãƒ³ã‚·', sg['requirement_met'], f"{sg['average_ms']:.2f}ms < 100ms"))
        
        if 'data_processing' in self.results:
            dp = self.results['data_processing']
            requirements_met.append(('ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ', dp['requirement_met'], f"{dp['throughput_per_sec']:.0f}/s â‰¥ 1000/s"))
        
        print("\nğŸ¯ è¦ä»¶é”æˆçŠ¶æ³:")
        for requirement, met, detail in requirements_met:
            status = "âœ… PASS" if met else "âŒ FAIL"
            print(f"  {requirement}: {status} ({detail})")
        
        # å…¨ä½“è©•ä¾¡
        all_met = all(met for _, met, _ in requirements_met)
        print(f"\nğŸ† ç·åˆè©•ä¾¡: {'âœ… å…¨è¦ä»¶é”æˆ' if all_met else 'âŒ è¦ä»¶æœªé”æˆã‚ã‚Š'}")
        
        return all_met

async def run_performance_benchmark():
    """æ€§èƒ½ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ"""
    print("ğŸš€ Phase2 æ€§èƒ½ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯é–‹å§‹")
    print("="*60)
    
    benchmark = PerformanceBenchmark()
    
    try:
        # å„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ
        await benchmark.benchmark_signal_generation_latency()
        await benchmark.benchmark_data_processing_throughput()
        await benchmark.benchmark_memory_usage()
        await benchmark.benchmark_concurrent_processing()
        
        # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        all_requirements_met = benchmark.generate_performance_report()
        
        return all_requirements_met
        
    except Exception as e:
        print(f"âŒ ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        return False

if __name__ == "__main__":
    success = asyncio.run(run_performance_benchmark())
    sys.exit(0 if success else 1)