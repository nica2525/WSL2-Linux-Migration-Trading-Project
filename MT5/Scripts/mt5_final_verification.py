#!/usr/bin/env python3
"""
MT5åŸå› ç‰¹å®šæœ€çµ‚æ¤œè¨¼ã‚·ã‚¹ãƒ†ãƒ 
ç›®çš„: ã€ŒMT5ã®ç‰¹æ®Šè¨˜éŒ²æ–¹å¼ã€ä»®èª¬ã®å¾¹åº•æ¤œè¨¼

æ¤œè¨¼é …ç›®:
1. æ™‚ç³»åˆ—é€†è»¢ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ä¸€è²«æ€§ç¢ºèª
2. ä»–ã®å¯èƒ½ãªåŸå› ã®å®Œå…¨æ’é™¤
3. MT5å‹•ä½œä»®èª¬ã®è«–ç†çš„æ•´åˆæ€§æ¤œè¨¼

ä½œæˆè€…: Claudeï¼ˆæœ€çµ‚åŸå› ç¢ºå®šæ‹…å½“ï¼‰
"""

import json
import logging
import re
from datetime import datetime
from typing import Dict

import pandas as pd


class MT5FinalVerification:
    """MT5åŸå› ç‰¹å®šæœ€çµ‚æ¤œè¨¼ã‚·ã‚¹ãƒ†ãƒ """

    def __init__(self, excel_path: str):
        self.excel_path = excel_path
        self.raw_data = None
        self.trades_df = None

        logging.basicConfig(
            level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
        )
        self.logger = logging.getLogger(__name__)

    def load_data_for_verification(self) -> bool:
        """æ¤œè¨¼ç”¨ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿"""
        try:
            self.raw_data = pd.read_excel(self.excel_path, header=None)

            header_row = 59
            data_start_row = 60

            header = self.raw_data.iloc[header_row].values
            data_rows = self.raw_data.iloc[data_start_row:].values

            self.trades_df = pd.DataFrame(data_rows, columns=header)
            self.trades_df = self.trades_df.dropna(how="all")

            self.logger.info(f"æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†: {len(self.trades_df)}ä»¶")
            return True

        except Exception as e:
            self.logger.error(f"ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return False

    def verify_time_reversal_hypothesis(self) -> Dict:
        """æ™‚ç³»åˆ—é€†è»¢ä»®èª¬ã®å¾¹åº•æ¤œè¨¼"""
        self.logger.info("=== æ™‚ç³»åˆ—é€†è»¢ä»®èª¬å¾¹åº•æ¤œè¨¼ ===")

        verification = {
            "hypothesis_tests": [],
            "alternative_explanations": [],
            "consistency_checks": [],
            "final_verdict": {},
        }

        # åˆ—å®šç¾©
        time_col = self.trades_df.columns[0]
        order_col = self.trades_df.columns[1]
        comment_col = self.trades_df.columns[12]

        # ãƒ†ã‚¹ãƒˆ1: æ™‚ç³»åˆ—é€†è»¢ã®ä¸€è²«æ€§ç¢ºèª
        self.logger.info("--- ãƒ†ã‚¹ãƒˆ1: æ™‚ç³»åˆ—é€†è»¢ãƒ‘ã‚¿ãƒ¼ãƒ³ä¸€è²«æ€§ ---")

        position_groups = self.trades_df.groupby(order_col)
        reversal_patterns = {
            "tp_first": 0,
            "sl_first": 0,
            "normal_order": 0,
            "inconsistent": 0,
        }

        test_sample = 0
        for _position_id, group in position_groups:
            if test_sample >= 1000:  # 1000ã‚µãƒ³ãƒ—ãƒ«ã§æ¤œè¨¼
                break

            if len(group) < 2:
                continue

            test_sample += 1

            # æ™‚ç³»åˆ—ã‚½ãƒ¼ãƒˆ
            group_sorted = group.sort_values(time_col)

            entry_rows = group_sorted[
                group_sorted[comment_col].astype(str).str.contains("JamesORB", na=False)
            ]
            exit_rows = group_sorted[
                group_sorted[comment_col].astype(str).str.contains("sl |tp ", na=False)
            ]

            if len(entry_rows) == 0 or len(exit_rows) == 0:
                continue

            try:
                entry_time = pd.to_datetime(
                    entry_rows.iloc[0][time_col], format="%Y.%m.%d %H:%M:%S"
                )
                exit_time = pd.to_datetime(
                    exit_rows.iloc[0][time_col], format="%Y.%m.%d %H:%M:%S"
                )
                exit_comment = str(exit_rows.iloc[0][comment_col]).lower()

                if exit_time < entry_time:
                    if "tp " in exit_comment:
                        reversal_patterns["tp_first"] += 1
                    elif "sl " in exit_comment:
                        reversal_patterns["sl_first"] += 1
                    else:
                        reversal_patterns["inconsistent"] += 1
                else:
                    reversal_patterns["normal_order"] += 1

            except:
                reversal_patterns["inconsistent"] += 1

        verification["hypothesis_tests"].append(
            {
                "test_name": "Time_Reversal_Pattern_Consistency",
                "sample_size": test_sample,
                "results": reversal_patterns,
                "conclusion": "CONSISTENT"
                if reversal_patterns["inconsistent"] < test_sample * 0.1
                else "INCONSISTENT",
            }
        )

        # ãƒ†ã‚¹ãƒˆ2: ä»£æ›¿ä»®èª¬æ¤œè¨¼
        self.logger.info("--- ãƒ†ã‚¹ãƒˆ2: ä»£æ›¿ä»®èª¬æ¤œè¨¼ ---")

        # ä»®èª¬A: ãƒ‡ãƒ¼ã‚¿ç ´æ
        data_corruption_indicators = {
            "duplicate_timestamps": 0,
            "invalid_timestamps": 0,
            "missing_data_patterns": 0,
        }

        timestamp_counts = self.trades_df[time_col].value_counts()
        data_corruption_indicators["duplicate_timestamps"] = (
            timestamp_counts > 10
        ).sum()

        # ä»®èª¬B: ç•°ãªã‚‹ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³
        timezone_test = self._test_timezone_hypothesis()

        # ä»®èª¬C: EAå®Ÿè¡Œé †åºå•é¡Œ
        ea_execution_test = self._test_ea_execution_hypothesis()

        verification["alternative_explanations"] = [
            {
                "hypothesis": "Data_Corruption",
                "indicators": data_corruption_indicators,
                "likelihood": "LOW"
                if data_corruption_indicators["duplicate_timestamps"] < 100
                else "HIGH",
            },
            {
                "hypothesis": "Timezone_Issues",
                "test_results": timezone_test,
                "likelihood": timezone_test["likelihood"],
            },
            {
                "hypothesis": "EA_Execution_Order",
                "test_results": ea_execution_test,
                "likelihood": ea_execution_test["likelihood"],
            },
        ]

        # ãƒ†ã‚¹ãƒˆ3: MT5ä»•æ§˜ã¨ã®æ•´åˆæ€§
        self.logger.info("--- ãƒ†ã‚¹ãƒˆ3: MT5ä»•æ§˜æ•´åˆæ€§ç¢ºèª ---")

        consistency_check = self._check_mt5_specification_consistency()
        verification["consistency_checks"].append(consistency_check)

        # æœ€çµ‚åˆ¤å®š
        verification["final_verdict"] = self._generate_final_verdict(verification)

        return verification

    def _test_timezone_hypothesis(self) -> Dict:
        """ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³ä»®èª¬ãƒ†ã‚¹ãƒˆ"""
        # æ™‚ç³»åˆ—é€†è»¢ã®æ™‚é–“å·®åˆ†æ
        time_col = self.trades_df.columns[0]
        order_col = self.trades_df.columns[1]
        comment_col = self.trades_df.columns[12]

        time_diffs = []
        position_groups = self.trades_df.groupby(order_col)

        for _position_id, group in list(position_groups)[:200]:
            if len(group) < 2:
                continue

            entry_rows = group[
                group[comment_col].astype(str).str.contains("JamesORB", na=False)
            ]
            exit_rows = group[
                group[comment_col].astype(str).str.contains("sl |tp ", na=False)
            ]

            if len(entry_rows) == 0 or len(exit_rows) == 0:
                continue

            try:
                entry_time = pd.to_datetime(
                    entry_rows.iloc[0][time_col], format="%Y.%m.%d %H:%M:%S"
                )
                exit_time = pd.to_datetime(
                    exit_rows.iloc[0][time_col], format="%Y.%m.%d %H:%M:%S"
                )

                if exit_time < entry_time:
                    time_diff_hours = (entry_time - exit_time).total_seconds() / 3600
                    time_diffs.append(time_diff_hours)
            except:
                continue

        if not time_diffs:
            return {"likelihood": "UNKNOWN", "reason": "No time differences found"}

        # ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³å·®ã®ç‰¹å¾´åˆ†æ
        avg_diff = sum(time_diffs) / len(time_diffs)

        # å…¸å‹çš„ãªã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³å·®ï¼ˆ1, 3, 8, 9, 12æ™‚é–“ç­‰ï¼‰ã«è¿‘ã„ã‹ãƒã‚§ãƒƒã‚¯
        common_tz_diffs = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]
        closest_tz_diff = min(common_tz_diffs, key=lambda x: abs(x - avg_diff))

        likelihood = "HIGH" if abs(avg_diff - closest_tz_diff) < 0.5 else "LOW"

        return {
            "likelihood": likelihood,
            "average_time_diff_hours": avg_diff,
            "closest_timezone_diff": closest_tz_diff,
            "sample_size": len(time_diffs),
        }

    def _test_ea_execution_hypothesis(self) -> Dict:
        """EAå®Ÿè¡Œé †åºä»®èª¬ãƒ†ã‚¹ãƒˆ"""
        # EAãŒæ±ºæ¸ˆæ³¨æ–‡ã‚’å…ˆã«åŸ·è¡Œã—ã€ã‚¨ãƒ³ãƒˆãƒªãƒ¼æ³¨æ–‡ã‚’å¾Œã‹ã‚‰è¨˜éŒ²ã™ã‚‹å¯èƒ½æ€§ã‚’ãƒ†ã‚¹ãƒˆ

        # åŒä¸€æ™‚åˆ»ã§ã®æ³¨æ–‡æ•°åˆ†æ
        time_col = self.trades_df.columns[0]
        comment_col = self.trades_df.columns[12]

        simultaneous_orders = []
        timestamp_groups = self.trades_df.groupby(time_col)

        for timestamp, group in timestamp_groups:
            if len(group) > 1:
                entry_count = len(
                    group[
                        group[comment_col]
                        .astype(str)
                        .str.contains("JamesORB", na=False)
                    ]
                )
                exit_count = len(
                    group[
                        group[comment_col].astype(str).str.contains("sl |tp ", na=False)
                    ]
                )

                if entry_count > 0 and exit_count > 0:
                    simultaneous_orders.append(
                        {
                            "timestamp": timestamp,
                            "entry_count": entry_count,
                            "exit_count": exit_count,
                            "total": len(group),
                        }
                    )

        likelihood = "HIGH" if len(simultaneous_orders) > 100 else "LOW"

        return {
            "likelihood": likelihood,
            "simultaneous_order_events": len(simultaneous_orders),
            "sample_events": simultaneous_orders[:5],
        }

    def _check_mt5_specification_consistency(self) -> Dict:
        """MT5ä»•æ§˜ã¨ã®æ•´åˆæ€§ç¢ºèª"""

        # MT5ã®æ—¢çŸ¥ã®å‹•ä½œãƒ‘ã‚¿ãƒ¼ãƒ³ã¨ã®ç…§åˆ
        consistency_indicators = {
            "position_id_sequential": self._check_position_id_sequence(),
            "comment_format_standard": self._check_comment_format(),
            "price_precision_consistent": self._check_price_precision(),
            "timestamp_format_valid": self._check_timestamp_format(),
        }

        overall_consistency = sum(
            1 for v in consistency_indicators.values() if v
        ) / len(consistency_indicators)

        return {
            "test_name": "MT5_Specification_Consistency",
            "indicators": consistency_indicators,
            "overall_consistency_score": overall_consistency,
            "conclusion": "CONSISTENT" if overall_consistency > 0.8 else "INCONSISTENT",
        }

    def _check_position_id_sequence(self) -> bool:
        """position_idé€£ç¶šæ€§ãƒã‚§ãƒƒã‚¯"""
        order_col = self.trades_df.columns[1]
        position_ids = self.trades_df[order_col].dropna().unique()

        # æ•°å€¤ã¨ã—ã¦æ‰±ãˆã‚‹position_idã®é€£ç¶šæ€§ãƒã‚§ãƒƒã‚¯
        numeric_ids = []
        for pid in position_ids:
            try:
                numeric_ids.append(int(pid))
            except:
                continue

        if len(numeric_ids) < 100:
            return False

        numeric_ids.sort()
        gaps = [
            numeric_ids[i + 1] - numeric_ids[i] for i in range(len(numeric_ids) - 1)
        ]
        avg_gap = sum(gaps) / len(gaps)

        # å¹³å‡ã‚®ãƒ£ãƒƒãƒ—ãŒå°ã•ã‘ã‚Œã°é€£ç¶šæ€§ã‚ã‚Š
        return avg_gap < 5

    def _check_comment_format(self) -> bool:
        """ã‚³ãƒ¡ãƒ³ãƒˆå½¢å¼ã®æ¨™æº–æ€§ãƒã‚§ãƒƒã‚¯"""
        comment_col = self.trades_df.columns[12]
        comments = self.trades_df[comment_col].dropna().astype(str)

        # JamesORB, sl, tp ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ¯”ç‡
        jamesorb_count = comments.str.contains("JamesORB", na=False).sum()
        sl_count = comments.str.contains("sl ", na=False).sum()
        tp_count = comments.str.contains("tp ", na=False).sum()

        total_relevant = jamesorb_count + sl_count + tp_count
        coverage_ratio = total_relevant / len(comments)

        return coverage_ratio > 0.8

    def _check_price_precision(self) -> bool:
        """ä¾¡æ ¼ç²¾åº¦ã®ä¸€è²«æ€§ãƒã‚§ãƒƒã‚¯"""
        price_col = self.trades_df.columns[6]
        prices = pd.to_numeric(self.trades_df[price_col], errors="coerce").dropna()

        # ä¾¡æ ¼ã®å°æ•°ç‚¹ç²¾åº¦ãƒã‚§ãƒƒã‚¯
        decimal_places = []
        for price in prices.head(1000):
            price_str = f"{price:.10f}".rstrip("0")
            if "." in price_str:
                decimal_places.append(len(price_str.split(".")[1]))
            else:
                decimal_places.append(0)

        # EURUSDæ¨™æº–ã®5æ¡ç²¾åº¦ãŒå¤šæ•°ã‚’å ã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        five_decimal_ratio = sum(1 for dp in decimal_places if dp == 5) / len(
            decimal_places
        )

        return five_decimal_ratio > 0.7

    def _check_timestamp_format(self) -> bool:
        """ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—å½¢å¼ã®å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯"""
        time_col = self.trades_df.columns[0]
        timestamps = self.trades_df[time_col].dropna().astype(str)

        # YYYY.MM.DD HH:MM:SS å½¢å¼ã®å‰²åˆãƒã‚§ãƒƒã‚¯
        valid_format_count = 0
        for ts in timestamps.head(1000):
            if re.match(r"^\d{4}\.\d{2}\.\d{2} \d{2}:\d{2}:\d{2}$", ts):
                valid_format_count += 1

        return valid_format_count / min(len(timestamps), 1000) > 0.95

    def _generate_final_verdict(self, verification: Dict) -> Dict:
        """æœ€çµ‚åˆ¤å®šç”Ÿæˆ"""

        # å„ãƒ†ã‚¹ãƒˆçµæœã®é‡ã¿ä»˜ã‘è©•ä¾¡
        scores = {
            "time_reversal_consistency": 0,
            "alternative_explanations": 0,
            "mt5_specification": 0,
        }

        # æ™‚ç³»åˆ—é€†è»¢ä¸€è²«æ€§ã‚¹ã‚³ã‚¢
        for test in verification["hypothesis_tests"]:
            if test["test_name"] == "Time_Reversal_Pattern_Consistency":
                if test["conclusion"] == "CONSISTENT":
                    scores["time_reversal_consistency"] = 0.8
                else:
                    scores["time_reversal_consistency"] = 0.2

        # ä»£æ›¿ä»®èª¬ã‚¹ã‚³ã‚¢ï¼ˆä»£æ›¿ä»®èª¬ãŒä½ç¢ºç‡ãªã‚‰å…ƒä»®èª¬ã‚’æ”¯æŒï¼‰
        high_likelihood_alternatives = sum(
            1
            for alt in verification["alternative_explanations"]
            if alt["likelihood"] == "HIGH"
        )
        scores["alternative_explanations"] = (
            0.8 if high_likelihood_alternatives == 0 else 0.2
        )

        # MT5ä»•æ§˜æ•´åˆæ€§ã‚¹ã‚³ã‚¢
        for check in verification["consistency_checks"]:
            if check["test_name"] == "MT5_Specification_Consistency":
                scores["mt5_specification"] = check["overall_consistency_score"]

        # ç·åˆã‚¹ã‚³ã‚¢è¨ˆç®—
        total_score = sum(scores.values()) / len(scores)

        # ä¿¡é ¼åº¦åˆ¤å®š
        if total_score >= 0.8:
            confidence = "VERY_HIGH"
            verdict = "MT5ç‰¹æ®Šè¨˜éŒ²æ–¹å¼ä»®èª¬ã¯æ­£ã—ã„"
        elif total_score >= 0.6:
            confidence = "HIGH"
            verdict = "MT5ç‰¹æ®Šè¨˜éŒ²æ–¹å¼ä»®èª¬ã¯æ¦‚ã­æ­£ã—ã„"
        elif total_score >= 0.4:
            confidence = "MODERATE"
            verdict = "MT5ç‰¹æ®Šè¨˜éŒ²æ–¹å¼ä»®èª¬ã¯éƒ¨åˆ†çš„ã«æ­£ã—ã„"
        else:
            confidence = "LOW"
            verdict = "MT5ç‰¹æ®Šè¨˜éŒ²æ–¹å¼ä»®èª¬ã¯ç–‘ã‚ã—ã„"

        return {
            "overall_confidence": confidence,
            "total_score": total_score,
            "component_scores": scores,
            "final_verdict": verdict,
            "recommendation": self._generate_recommendation(confidence, total_score),
        }

    def _generate_recommendation(self, confidence: str, score: float) -> str:
        """æ¨å¥¨äº‹é …ç”Ÿæˆ"""
        if confidence in ["VERY_HIGH", "HIGH"]:
            return "MT5ã®ç‰¹æ®Šè¨˜éŒ²æ–¹å¼ã¨ã—ã¦å—ã‘å…¥ã‚Œã€ã“ã®å‰æã§çµ±è¨ˆåˆ†æã‚’å®Ÿè¡Œã™ã‚‹ã“ã¨ã‚’æ¨å¥¨"
        elif confidence == "MODERATE":
            return "è¿½åŠ æ¤œè¨¼ã‚’å®Ÿæ–½ã—ã€ã‚ˆã‚Šå¤šãã®ãƒ‡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒ«ã§ã®ç¢ºèªã‚’æ¨å¥¨"
        else:
            return "åŸå› ä»®èª¬ã®å†æ¤œè¨ãŒå¿…è¦ã€‚åˆ¥ã®æŠ€è¡“çš„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’æ¤œè¨ã™ã‚‹ã“ã¨ã‚’æ¨å¥¨"

    def run_final_verification(self) -> Dict:
        """æœ€çµ‚æ¤œè¨¼å®Ÿè¡Œ"""
        self.logger.info("ğŸ” === MT5åŸå› ç‰¹å®šæœ€çµ‚æ¤œè¨¼é–‹å§‹ ===")

        if not self.load_data_for_verification():
            return {"error": "Failed to load data"}

        verification_result = self.verify_time_reversal_hypothesis()

        # çµæœä¿å­˜
        final_result = {
            "timestamp": datetime.now().isoformat(),
            "verification_method": "MT5_Time_Reversal_Hypothesis_Final_Verification",
            "verification_results": verification_result,
            "final_confidence_assessment": verification_result["final_verdict"],
        }

        output_path = "/home/trader/Trading-Development/2.ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆæ‰‹æ³•ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ/MT5_Results/final_verification_results.json"
        with open(output_path, "w", encoding="utf-8") as f:
            json.dump(final_result, f, indent=2, ensure_ascii=False, default=str)

        self.logger.info(f"âœ… æœ€çµ‚æ¤œè¨¼çµæœä¿å­˜: {output_path}")
        self.logger.info(
            f"ğŸ¯ æœ€çµ‚åˆ¤å®š: {verification_result['final_verdict']['final_verdict']}"
        )
        self.logger.info(
            f"ğŸ“Š ä¿¡é ¼åº¦: {verification_result['final_verdict']['overall_confidence']}"
        )

        return final_result


def main():
    """æœ€çµ‚æ¤œè¨¼å®Ÿè¡Œ"""
    excel_path = "/home/trader/Trading-Development/2.ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆæ‰‹æ³•ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ/MT5_Results/Reportãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆ-900179988.xlsx"

    verifier = MT5FinalVerification(excel_path)
    results = verifier.run_final_verification()

    return results


if __name__ == "__main__":
    main()
