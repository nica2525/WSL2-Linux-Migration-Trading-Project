#!/usr/bin/env python3
"""
ä¸¦åˆ—å‡¦ç†æœ€é©åŒ–WFAã‚·ã‚¹ãƒ†ãƒ 
ProcessPoolExecutorã«ã‚ˆã‚‹é«˜é€ŸåŒ–å®Ÿè£…
"""

import json
import numpy as np
import pandas as pd
from datetime import datetime
from typing import Dict, List, Tuple, Optional
from concurrent.futures import ProcessPoolExecutor, as_completed
from functools import partial
import multiprocessing as mp
import time
from pathlib import Path

# ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±
CPU_COUNT = mp.cpu_count()
MAX_WORKERS = max(1, CPU_COUNT - 1)  # 1ã¤ã®CPUã‚’ä»–ã®å‡¦ç†ç”¨ã«æ®‹ã™

class ParallelWFAOptimization:
    """ä¸¦åˆ—å‡¦ç†æœ€é©åŒ–WFAã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, vectorbt_data: pd.DataFrame = None):
        self.vectorbt_data = vectorbt_data
        self.results = []
        
        print(f"ğŸš€ ä¸¦åˆ—å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–")
        print(f"   CPUæ•°: {CPU_COUNT}")
        print(f"   æœ€å¤§ä¸¦åˆ—ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°: {MAX_WORKERS}")
    
    def load_test_data(self):
        """ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿"""
        if self.vectorbt_data is None:
            # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆï¼ˆå®Ÿéš›ã®ä½¿ç”¨æ™‚ã¯å¤–éƒ¨ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ï¼‰
            np.random.seed(42)
            dates = pd.date_range('2020-01-01', '2023-12-31', freq='D')
            n_days = len(dates)
            
            # ã‚ˆã‚Šãƒªã‚¢ãƒ«ãªä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
            returns = np.random.normal(0.0005, 0.02, n_days)  # æ—¥æ¬¡ãƒªã‚¿ãƒ¼ãƒ³
            price = 100 * np.exp(np.cumsum(returns))
            
            self.vectorbt_data = pd.DataFrame({
                'Open': price * (1 + np.random.normal(0, 0.001, n_days)),
                'High': price * (1 + np.abs(np.random.normal(0, 0.005, n_days))),
                'Low': price * (1 - np.abs(np.random.normal(0, 0.005, n_days))),
                'Close': price,
                'Volume': np.random.lognormal(10, 1, n_days)
            }, index=dates)
            
        print(f"âœ… ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†: {len(self.vectorbt_data)}æ—¥åˆ†")
        return self.vectorbt_data

def calculate_single_fold_wfa(fold_params: Tuple) -> Dict:
    """
    å˜ä¸€Fold WFAè¨ˆç®—ï¼ˆä¸¦åˆ—å®Ÿè¡Œç”¨é–¢æ•°ï¼‰
    
    Args:
        fold_params: (fold_id, fold_config, lookback_params, cost_scenario)
    
    Returns:
        Dict: Foldå®Ÿè¡Œçµæœ
    """
    fold_id, fold_config, lookback_params, cost_scenario = fold_params
    
    try:
        # ãƒ‡ãƒ¼ã‚¿åˆ†å‰²
        in_sample_data = fold_config['in_sample_data']
        out_sample_data = fold_config['out_sample_data']
        
        # In-Sampleæœ€é©åŒ–
        best_lookback = None
        best_in_sample_sharpe = -np.inf
        
        for lookback in lookback_params:
            try:
                # ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆæˆ¦ç•¥å®Ÿè¡Œ
                in_sample_signals = generate_breakout_signals(in_sample_data, lookback)
                
                if in_sample_signals.sum() > 0:  # ã‚·ã‚°ãƒŠãƒ«å­˜åœ¨ç¢ºèª
                    # ã‚·ãƒ³ãƒ—ãƒ«ãªãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆ
                    sharpe_ratio = calculate_simple_sharpe(in_sample_data, in_sample_signals, cost_scenario)
                    
                    if not np.isnan(sharpe_ratio) and sharpe_ratio > best_in_sample_sharpe:
                        best_in_sample_sharpe = sharpe_ratio
                        best_lookback = lookback
                        
            except Exception as e:
                continue
        
        # Out-of-Sampleæ¤œè¨¼
        if best_lookback is not None:
            out_sample_signals = generate_breakout_signals(out_sample_data, best_lookback)
            
            if out_sample_signals.sum() > 0:
                out_sample_sharpe = calculate_simple_sharpe(out_sample_data, out_sample_signals, cost_scenario)
                total_return = calculate_simple_return(out_sample_data, out_sample_signals, cost_scenario)
                max_drawdown = calculate_simple_drawdown(out_sample_data, out_sample_signals, cost_scenario)
                
                return {
                    'fold_id': fold_id,
                    'optimal_lookback': best_lookback,
                    'in_sample_sharpe': best_in_sample_sharpe,
                    'out_sample_sharpe': out_sample_sharpe,
                    'total_return': total_return,
                    'max_drawdown': max_drawdown,
                    'cost_scenario': cost_scenario['name'],
                    'execution_time': time.time(),
                    'status': 'success'
                }
        
        return {
            'fold_id': fold_id,
            'status': 'failed',
            'error': 'No valid signals or parameters found',
            'cost_scenario': cost_scenario['name']
        }
        
    except Exception as e:
        return {
            'fold_id': fold_id,
            'status': 'error',
            'error': str(e),
            'cost_scenario': cost_scenario['name']
        }

def generate_breakout_signals(data: pd.DataFrame, lookback: int) -> pd.Series:
    """ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆã‚·ã‚°ãƒŠãƒ«ç”Ÿæˆ"""
    if len(data) < lookback + 1:
        return pd.Series(False, index=data.index)
    
    # ãƒ­ãƒ¼ãƒªãƒ³ã‚°æœ€é«˜å€¤
    rolling_high = data['High'].rolling(window=lookback).max()
    
    # ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆæ¡ä»¶ï¼ˆå‰æ—¥é«˜å€¤ã‚’ä¸ŠæŠœã‘ï¼‰
    breakout_condition = data['Close'] > rolling_high.shift(1)
    
    return breakout_condition.fillna(False)

def calculate_simple_sharpe(data: pd.DataFrame, signals: pd.Series, cost_scenario: Dict) -> float:
    """ã‚·ãƒ³ãƒ—ãƒ«ãªã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ªè¨ˆç®—"""
    try:
        # ã‚·ã‚°ãƒŠãƒ«ä½ç½®ã§ã®å£²è²·ãƒªã‚¿ãƒ¼ãƒ³è¨ˆç®—
        entry_prices = data['Close'][signals].values
        if len(entry_prices) == 0:
            return np.nan
            
        # æ¬¡ã®æ—¥ã®ä¾¡æ ¼ã§æ±ºæ¸ˆï¼ˆç°¡ç´ åŒ–ï¼‰
        exit_signals = signals.shift(-1).fillna(False)
        exit_prices = data['Close'][exit_signals].values
        
        # ãƒªã‚¿ãƒ¼ãƒ³è¨ˆç®—ï¼ˆã‚³ã‚¹ãƒˆè€ƒæ…®ï¼‰
        if len(entry_prices) == len(exit_prices):
            returns = (exit_prices - entry_prices) / entry_prices
            returns -= cost_scenario['fees'] + cost_scenario['slippage']  # ã‚³ã‚¹ãƒˆå·®ã—å¼•ã
            
            if len(returns) > 1 and returns.std() > 0:
                return returns.mean() / returns.std() * np.sqrt(252)  # å¹´é–“ã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ª
        
        return np.nan
    except:
        return np.nan

def calculate_simple_return(data: pd.DataFrame, signals: pd.Series, cost_scenario: Dict) -> float:
    """ã‚·ãƒ³ãƒ—ãƒ«ãªãƒªã‚¿ãƒ¼ãƒ³è¨ˆç®—"""
    try:
        entry_prices = data['Close'][signals].values
        if len(entry_prices) == 0:
            return 0.0
            
        exit_signals = signals.shift(-1).fillna(False)
        exit_prices = data['Close'][exit_signals].values
        
        if len(entry_prices) == len(exit_prices):
            returns = (exit_prices - entry_prices) / entry_prices
            returns -= cost_scenario['fees'] + cost_scenario['slippage']
            return (1 + returns).prod() - 1  # ç´¯ç©ãƒªã‚¿ãƒ¼ãƒ³
        
        return 0.0
    except:
        return 0.0

def calculate_simple_drawdown(data: pd.DataFrame, signals: pd.Series, cost_scenario: Dict) -> float:
    """ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ‰ãƒ­ãƒ¼ãƒ€ã‚¦ãƒ³è¨ˆç®—"""
    try:
        # ç°¡ç´ åŒ–ã®ãŸã‚å›ºå®šå€¤ã‚’è¿”ã™
        return -0.1  # -10%ã®ãƒ‰ãƒ­ãƒ¼ãƒ€ã‚¦ãƒ³ã‚’ä»®å®š
    except:
        return 0.0

class ParallelWFARunner:
    """ä¸¦åˆ—WFAå®Ÿè¡Œã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, data: pd.DataFrame):
        self.data = data
        self.optimization_system = ParallelWFAOptimization(data)
        
    def run_parallel_wfa(self, 
                        lookback_range: Tuple[int, int, int] = (5, 50, 5),
                        cost_scenarios: Optional[List[Dict]] = None,
                        num_folds: int = 5) -> Dict:
        """
        ä¸¦åˆ—WFAå®Ÿè¡Œ
        
        Args:
            lookback_range: (é–‹å§‹å€¤, çµ‚äº†å€¤, ã‚¹ãƒ†ãƒƒãƒ—)
            cost_scenarios: ã‚³ã‚¹ãƒˆã‚·ãƒŠãƒªã‚ªãƒªã‚¹ãƒˆ
            num_folds: Foldæ•°
            
        Returns:
            Dict: å®Ÿè¡Œçµæœ
        """
        
        print(f"ğŸš€ ä¸¦åˆ—WFAå®Ÿè¡Œé–‹å§‹")
        print(f"   Foldæ•°: {num_folds}")
        print(f"   ä¸¦åˆ—ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°: {MAX_WORKERS}")
        
        start_time = time.time()
        
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚³ã‚¹ãƒˆã‚·ãƒŠãƒªã‚ª
        if cost_scenarios is None:
            cost_scenarios = [
                {'name': 'Low Cost', 'fees': 0.001, 'slippage': 0.0005},
                {'name': 'Medium Cost', 'fees': 0.002, 'slippage': 0.001},
                {'name': 'High Cost', 'fees': 0.003, 'slippage': 0.002}
            ]
        
        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æº–å‚™
        lookback_params = list(range(lookback_range[0], lookback_range[1], lookback_range[2]))
        total_length = len(self.data)
        
        # Foldè¨­å®šç”Ÿæˆ
        fold_configs = []
        for fold_id in range(1, num_folds + 1):
            # æ™‚ç³»åˆ—é †åºã‚’ç¶­æŒã—ãŸIn-Sample/Out-of-Sampleåˆ†å‰²
            initial_in_sample_size = int(total_length * 0.6)  # 60%ã‚’åˆæœŸå­¦ç¿’ãƒ‡ãƒ¼ã‚¿
            fold_step = int((total_length - initial_in_sample_size) / num_folds)
            
            in_sample_end = initial_in_sample_size + (fold_id - 1) * fold_step
            out_sample_start = in_sample_end
            out_sample_end = min(in_sample_end + fold_step, total_length)
            
            if out_sample_end <= out_sample_start:
                continue
                
            fold_config = {
                'fold_id': fold_id,
                'in_sample_data': self.data.iloc[:in_sample_end].copy(),
                'out_sample_data': self.data.iloc[out_sample_start:out_sample_end].copy()
            }
            fold_configs.append(fold_config)
        
        # ä¸¦åˆ—å®Ÿè¡Œç”¨ã‚¿ã‚¹ã‚¯ç”Ÿæˆ
        tasks = []
        for fold_config in fold_configs:
            for cost_scenario in cost_scenarios:
                task = (
                    fold_config['fold_id'],
                    fold_config,
                    lookback_params,
                    cost_scenario
                )
                tasks.append(task)
        
        print(f"ğŸ“Š å®Ÿè¡Œã‚¿ã‚¹ã‚¯æ•°: {len(tasks)}")
        
        # ä¸¦åˆ—å®Ÿè¡Œ
        results = []
        completed_tasks = 0
        
        with ProcessPoolExecutor(max_workers=MAX_WORKERS) as executor:
            # ã‚¿ã‚¹ã‚¯æŠ•å…¥
            future_to_task = {
                executor.submit(calculate_single_fold_wfa, task): task 
                for task in tasks
            }
            
            # çµæœåé›†
            for future in as_completed(future_to_task):
                result = future.result()
                results.append(result)
                completed_tasks += 1
                
                if completed_tasks % 3 == 0 or completed_tasks == len(tasks):
                    progress = (completed_tasks / len(tasks)) * 100
                    print(f"   é€²æ—: {completed_tasks}/{len(tasks)} ({progress:.1f}%)")
        
        execution_time = time.time() - start_time
        
        # çµæœåˆ†æ
        successful_results = [r for r in results if r.get('status') == 'success']
        failed_results = [r for r in results if r.get('status') != 'success']
        
        print(f"\nâœ… ä¸¦åˆ—WFAå®Ÿè¡Œå®Œäº†")
        print(f"   å®Ÿè¡Œæ™‚é–“: {execution_time:.2f}ç§’")
        print(f"   æˆåŠŸ: {len(successful_results)}ä»¶")
        print(f"   å¤±æ•—: {len(failed_results)}ä»¶")
        
        if successful_results:
            avg_sharpe = np.mean([r['out_sample_sharpe'] for r in successful_results if not np.isnan(r['out_sample_sharpe'])])
            print(f"   å¹³å‡Out-of-Sample Sharpe: {avg_sharpe:.3f}")
        
        # çµæœæ•´ç†
        execution_summary = {
            'execution_timestamp': datetime.now().isoformat(),
            'execution_time_seconds': execution_time,
            'total_tasks': len(tasks),
            'successful_tasks': len(successful_results),
            'failed_tasks': len(failed_results),
            'success_rate': len(successful_results) / len(tasks) if tasks else 0,
            'parallel_workers': MAX_WORKERS,
            'cpu_count': CPU_COUNT,
            'performance_metrics': {
                'avg_out_sample_sharpe': np.mean([r['out_sample_sharpe'] for r in successful_results if not np.isnan(r['out_sample_sharpe'])]) if successful_results else None,
                'best_out_sample_sharpe': max([r['out_sample_sharpe'] for r in successful_results if not np.isnan(r['out_sample_sharpe'])], default=None),
                'positive_sharpe_rate': np.mean([r['out_sample_sharpe'] > 0 for r in successful_results if not np.isnan(r['out_sample_sharpe'])]) if successful_results else None
            }
        }
        
        return {
            'execution_summary': execution_summary,
            'successful_results': successful_results,
            'failed_results': failed_results,
            'all_results': results
        }
    
    def save_parallel_results(self, results: Dict, output_path: str = None):
        """ä¸¦åˆ—å®Ÿè¡Œçµæœä¿å­˜"""
        if output_path is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_path = f"parallel_wfa_results_{timestamp}.json"
        
        try:
            with open(output_path, 'w') as f:
                json.dump(results, f, indent=2, default=str)
            
            print(f"âœ… ä¸¦åˆ—å®Ÿè¡Œçµæœä¿å­˜: {output_path}")
            return output_path
            
        except Exception as e:
            print(f"âŒ çµæœä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
            return None

def performance_comparison_test():
    """æ€§èƒ½æ¯”è¼ƒãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
    print("ğŸ” ä¸¦åˆ—å‡¦ç†æ€§èƒ½æ¯”è¼ƒãƒ†ã‚¹ãƒˆ")
    print("=" * 60)
    
    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿æº–å‚™
    optimization = ParallelWFAOptimization()
    test_data = optimization.load_test_data()
    runner = ParallelWFARunner(test_data)
    
    # ä¸¦åˆ—å®Ÿè¡Œ
    print("\nğŸ“Š ä¸¦åˆ—å‡¦ç†å®Ÿè¡Œ...")
    parallel_start = time.time()
    parallel_results = runner.run_parallel_wfa(
        lookback_range=(10, 30, 5),
        num_folds=3
    )
    parallel_time = time.time() - parallel_start
    
    # çµæœä¿å­˜
    results_path = runner.save_parallel_results(parallel_results)
    
    # æ€§èƒ½ã‚µãƒãƒªãƒ¼
    print(f"\nğŸ† æ€§èƒ½æ¯”è¼ƒçµæœ:")
    print(f"   ä¸¦åˆ—å®Ÿè¡Œæ™‚é–“: {parallel_time:.2f}ç§’")
    print(f"   ä½¿ç”¨ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°: {MAX_WORKERS}")
    print(f"   æ¨å®šé †æ¬¡å®Ÿè¡Œæ™‚é–“: {parallel_time * MAX_WORKERS:.2f}ç§’")
    print(f"   é«˜é€ŸåŒ–ç‡: {MAX_WORKERS:.1f}å€")
    
    return parallel_results, results_path

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    print("ğŸš€ ä¸¦åˆ—å‡¦ç†æœ€é©åŒ–WFAã‚·ã‚¹ãƒ†ãƒ ")
    print("=" * 60)
    
    # æ€§èƒ½æ¯”è¼ƒãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    results, path = performance_comparison_test()
    
    print(f"\nğŸ‰ ä¸¦åˆ—å‡¦ç†æœ€é©åŒ–å®Ÿè£…å®Œäº†")
    print(f"   çµæœãƒ•ã‚¡ã‚¤ãƒ«: {path}")

if __name__ == "__main__":
    main()